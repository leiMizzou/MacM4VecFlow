#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ç³»ç»Ÿå·¥å…·æ¨¡å— - æä¾›ç³»ç»Ÿçº§åˆ«çš„ä¼˜åŒ–å’Œç›‘æ§åŠŸèƒ½
"""

import os
import time
import platform
import psutil
import gc
import threading
from threading import Timer, RLock
import traceback
import torch
import logging
from config import logger, SYSTEM_HEALTHY, CPU_CORES

# å°†è®¾å¤‡å˜é‡å¯¼å‡ºåˆ°å…¨å±€å‘½åç©ºé—´
device = None

# åˆå§‹åŒ–è®¾å¤‡ç±»å‹
def init_device():
    """åˆå§‹åŒ–è®¾å¤‡å¹¶è®¾ç½®ä¸ºå…¨å±€å˜é‡"""
    global device
    
    if torch.backends.mps.is_available():
        device = "mps"
        logger.info(f"âœ… ä½¿ç”¨ Apple MPS (M4 GPU) åŠ é€Ÿ")
        # åº”ç”¨ MPS å¢å¼ºä¼˜åŒ–
        enhance_mps_performance()
        # é…ç½® PyTorch çº¿ç¨‹
        torch.set_num_threads(CPU_CORES // 2)
        logger.info(f"âœ“ PyTorch çº¿ç¨‹é…ç½®: {CPU_CORES // 2}")
    else:
        device = "cpu"
        logger.info("âš ï¸ MPS ä¸å¯ç”¨ï¼Œä½¿ç”¨ CPU è®¡ç®—")
    
    # è¿”å›è®¾å¤‡ç±»å‹ä»¥ä¾›è°ƒç”¨è€…ä½¿ç”¨
    return device

def optimize_system_for_m4():
    """Optimize system settings for M4 chip"""
    # Only apply these optimizations on macOS with Apple Silicon
    if platform.system() != 'Darwin' or 'arm64' not in platform.machine():
        logger.info("âš ï¸ é Apple Silicon Macï¼Œè·³è¿‡ç³»ç»Ÿä¼˜åŒ–")
        return
    
    logger.info("ğŸ”§ åº”ç”¨ M4 ç³»ç»Ÿä¼˜åŒ–...")
    
    # 1. Set process priority (nice) if running with proper permissions
    try:
        os.nice(-10)  # Higher priority (lower nice value)
        logger.info("  âœ“ è¿›ç¨‹ä¼˜å…ˆçº§å·²æé«˜")
    except:
        logger.info("  âš ï¸ æ— æ³•è®¾ç½®è¿›ç¨‹ä¼˜å…ˆçº§")
    
    # 2. Optimize NumPy configuration
    try:
        # Use Apple Accelerate framework for NumPy
        os.environ["VECLIB_MAXIMUM_THREADS"] = str(CPU_CORES)
        logger.info(f"  âœ“ NumPy é…ç½®ä¼˜åŒ–ï¼Œä½¿ç”¨ Accelerate æ¡†æ¶ï¼Œæœ€å¤§çº¿ç¨‹: {CPU_CORES}")
    except:
        pass
    
    # 3. Memory allocation tuning
    try:
        os.environ["PYTHONMALLOC"] = "malloc"
        os.environ["MALLOC_TRIM_THRESHOLD_"] = "131072"  # 128KB
        logger.info("  âœ“ å†…å­˜åˆ†é…å™¨å·²ä¼˜åŒ–")
    except:
        pass
    
    # 4. Configure Python GC for high-performance computing
    try:
        gc.set_threshold(100000, 5, 5)  # Less frequent collections
        logger.info("  âœ“ åƒåœ¾å›æ”¶å™¨å·²ä¼˜åŒ–")
    except:
        pass
        
    logger.info("âœ… ç³»ç»Ÿä¼˜åŒ–å®Œæˆ")

def enhance_mps_performance():
    """å¢å¼ºM4èŠ¯ç‰‡MPSçš„æ€§èƒ½ä¼˜åŒ–"""
    if not torch.backends.mps.is_available():
        logger.info("âš ï¸ MPSä¸å¯ç”¨ï¼Œè·³è¿‡MPSä¼˜åŒ–")
        return False
        
    logger.info("ğŸš€ æ­£åœ¨åº”ç”¨å¢å¼ºçš„MPSä¼˜åŒ–...")
    
    # 1. è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä¼˜åŒ–MPS
    os.environ["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"  # ä¸»åŠ¨å†…å­˜ç®¡ç†
    os.environ["PYTORCH_MPS_ALLOCATOR_POLICY"] = "1"        # æ›´ä¼˜çš„åˆ†é…ç­–ç•¥
    
    # 2. å¯ç”¨å¼‚æ­¥MPSæ‰§è¡Œ
    if hasattr(torch.mps, 'enable_async'):
        torch.mps.enable_async(True)
        logger.info("  âœ“ å¯ç”¨MPSå¼‚æ­¥æ‰§è¡Œ")
    elif hasattr(torch.mps, 'set_async_execution'):
        torch.mps.set_async_execution(True)
        logger.info("  âœ“ å¯ç”¨MPSå¼‚æ­¥æ‰§è¡Œ")
    
    # 3. é…ç½®Metalç¼–è¯‘å™¨ä¼˜åŒ–
    os.environ["MTL_SHADER_VALIDATION"] = "0"    # ç¦ç”¨shaderéªŒè¯æé«˜æ€§èƒ½
    os.environ["MTL_SHADER_CACHE_MODE"] = "11"   # ä¼˜åŒ–shaderç¼“å­˜
    
    # 4. é¢„çƒ­MPSè®¾å¤‡
    try:
        # åˆ›å»ºéšæœºæ•°æ®æ¥é¢„çƒ­å›¾å½¢ç®¡é“
        for size in [128, 384, 768, 1024]:
            dummy = torch.rand(size, size, device="mps")
            _ = dummy @ dummy.T  # çŸ©é˜µä¹˜æ³•é¢„çƒ­
            del dummy
            
        # å¯¹äºåµŒå…¥æ¨¡å‹çš„å…³é”®æ“ä½œé¢„çƒ­
        seq_len, dim = 128, 384
        q = torch.rand(1, seq_len, dim, device="mps")
        k = torch.rand(1, seq_len, dim, device="mps")
        v = torch.rand(1, seq_len, dim, device="mps")
        
        # é¢„çƒ­æ³¨æ„åŠ›è®¡ç®—
        qk = torch.matmul(q, k.transpose(1, 2))
        qk = qk / (dim ** 0.5)
        attn = torch.nn.functional.softmax(qk, dim=-1)
        _ = torch.matmul(attn, v)
        
        # æ¸…ç†
        del q, k, v, qk, attn
        torch.mps.empty_cache()
        
        logger.info("  âœ“ MPSå›¾å½¢ç®¡é“é¢„çƒ­å®Œæˆ")
    except Exception as e:
        logger.warning(f"  âš ï¸ MPSé¢„çƒ­è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    
    # 5. é…ç½®MPSå†…å­˜ä¼˜åŒ–
    try:
        # ä¸»åŠ¨é‡Šæ”¾å†…å­˜å¹¶å°è¯•ä¿æŒè¾ƒä½çš„å†…å­˜å ç”¨
        torch.mps.empty_cache()
        
        # å»ºè®®ä½¿ç”¨çš„æœ€å¤§å†…å­˜å¤§å°
        # è¿™éœ€è¦PyTorchæ”¯æŒï¼Œæ¨¡æ‹Ÿç‰ˆæœ¬
        available_memory = psutil.virtual_memory().available
        suggested_max = min(int(available_memory * 0.7), 8 * 1024 * 1024 * 1024)  # æœ€å¤š8GB
        
        logger.info(f"  âœ“ MPSå†…å­˜ä¼˜åŒ–é…ç½®å®Œæˆï¼Œå»ºè®®æœ€å¤§ä½¿ç”¨: {suggested_max/(1024*1024*1024):.1f}GB")
        
        # è®¾ç½®è‡ªå®šä¹‰ç¼“å­˜é‡Šæ”¾ç›‘è§†å™¨
        class MPSMemoryMonitor:
            def __init__(self, threshold_mb=2000):
                self.threshold_mb = threshold_mb
                self.last_check = time.time()
                self.check_interval = 5  # ç§’
                
            def check(self):
                current_time = time.time()
                if current_time - self.last_check < self.check_interval:
                    return
                
                self.last_check = current_time
                try:
                    # è·å–MPSåˆ†é…çš„å†…å­˜
                    allocated = torch.mps.current_allocated_memory() / (1024 * 1024)
                    if allocated > self.threshold_mb:
                        logger.warning(f"  âš ï¸ MPSå†…å­˜ä½¿ç”¨è¾ƒé«˜: {allocated:.0f}MBï¼Œæ‰§è¡Œç¼“å­˜æ¸…ç†")
                        torch.mps.empty_cache()
                except:
                    pass
        
        # åˆ›å»ºç›‘è§†å™¨
        global mps_memory_monitor
        mps_memory_monitor = MPSMemoryMonitor(threshold_mb=4000)  # 4GBé˜ˆå€¼
        logger.info("  âœ“ MPSå†…å­˜ç›‘è§†å™¨å·²å¯åŠ¨")
    except Exception as e:
        logger.warning(f"  âš ï¸ é…ç½®MPSå†…å­˜ä¼˜åŒ–æ—¶å‡ºé”™: {e}")
    
    return True

def clean_memory(force_gc=False):
    """Efficiently clean up memory"""
    # ç¡®ä¿å…¨å±€å˜é‡å·²åˆå§‹åŒ–
    global device
    if device is None:
        init_device()
        
    if device == "mps":
        # Synchronize MPS stream before cleaning
        if hasattr(torch.mps, 'synchronize'):
            torch.mps.synchronize()
        torch.mps.empty_cache()
        
        # æ£€æŸ¥MPSå†…å­˜ç›‘è§†å™¨
        if 'mps_memory_monitor' in globals():
            mps_memory_monitor.check()
    
    if force_gc:
        # More aggressive cleanup
        for _ in range(2):  # Multiple collections can help with fragmentation
            gc.collect()

class SystemMonitor:
    """ç›‘æ§ç³»ç»Ÿå¥åº·çŠ¶æ€å¹¶åœ¨éœ€è¦æ—¶å¹²é¢„"""
    
    def __init__(self, timeout=180):
        self.timeout = timeout  # æ— è¿›åº¦è¶…æ—¶æ—¶é—´(ç§’)
        self.watchdog_timer = None
        self.active = False
        self.lock = threading.RLock()
        self.last_progress = time.time()
        
    def start(self):
        """å¯åŠ¨ç›‘æ§"""
        with self.lock:
            self.active = True
            self.last_progress = time.time()
            self._restart_timer()
            logger.info(f"ç³»ç»Ÿç›‘æ§å·²å¯åŠ¨ï¼Œæ— æ´»åŠ¨è¶…æ—¶æ—¶é—´: {self.timeout}ç§’")
            
    def stop(self):
        """åœæ­¢ç›‘æ§"""
        with self.lock:
            self.active = False
            if self.watchdog_timer:
                self.watchdog_timer.cancel()
            logger.info("ç³»ç»Ÿç›‘æ§å·²åœæ­¢")
            
    def update_progress(self):
        """æ›´æ–°è¿›åº¦æ—¶é—´æˆ³"""
        with self.lock:
            self.last_progress = time.time()
            self._restart_timer()
            
    def _restart_timer(self):
        """é‡å¯ç›‘æ§å®šæ—¶å™¨"""
        if self.watchdog_timer:
            self.watchdog_timer.cancel()
            
        if self.active:
            self.watchdog_timer = Timer(self.timeout, self._check_health)
            self.watchdog_timer.daemon = True
            self.watchdog_timer.start()
            
    def _check_health(self):
        """æ£€æŸ¥ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        global SYSTEM_HEALTHY
        
        current_time = time.time()
        elapsed = current_time - self.last_progress
        
        if elapsed > self.timeout:
            SYSTEM_HEALTHY = False
            logger.error(f"âš ï¸ ç³»ç»Ÿæ— å“åº”! {elapsed:.1f}ç§’æ— è¿›åº¦æ›´æ–°. è¯·æ£€æŸ¥å¤„ç†æµç¨‹æ˜¯å¦å¡ä½ã€‚")
            
            # è¾“å‡ºç³»ç»ŸçŠ¶æ€ä¿¡æ¯ç”¨äºè¯Šæ–­
            mem_info = psutil.virtual_memory()
            logger.error(f"ç³»ç»Ÿå†…å­˜: {mem_info.percent}% ä½¿ç”¨ä¸­, å¯ç”¨: {mem_info.available/(1024*1024*1024):.1f}GB")
            
            # è¾“å‡ºPythonçº¿ç¨‹ä¿¡æ¯
            logger.error("æ´»åŠ¨çº¿ç¨‹:")
            for thread in threading.enumerate():
                logger.error(f"  - {thread.name} ({'æ´»åŠ¨' if thread.is_alive() else 'éæ´»åŠ¨'})")
                
            # å¯åŠ¨æ–°çš„å®šæ—¶å™¨
            self._restart_timer()
        else:
            # ä¸€åˆ‡æ­£å¸¸ï¼Œé‡å¯å®šæ—¶å™¨
            self._restart_timer()

def optimize_pipeline_concurrency():
    """æ ¹æ®ç³»ç»Ÿç‰¹æ€§ä¼˜åŒ–æµæ°´çº¿å¹¶å‘åº¦"""
    # æ£€æµ‹å¯ç”¨ç‰©ç†æ ¸å¿ƒæ•°
    physical_cores = CPU_CORES
    
    # æ£€æµ‹æ˜¯å¦ä¸ºApple Silicon
    is_apple_silicon = (
        platform.system() == 'Darwin' and 
        platform.machine() == 'arm64'
    )
    
    # å¯¹M4èŠ¯ç‰‡ç‰¹åˆ«ä¼˜åŒ–
    if is_apple_silicon:
        # æ£€æµ‹å…·ä½“èŠ¯ç‰‡å‹å·
        try:
            import subprocess
            chip_info = subprocess.check_output(
                "sysctl -n machdep.cpu.brand_string", 
                shell=True
            ).decode().strip()
            
            is_m4 = "M4" in chip_info
            
            if is_m4:
                logger.info(f"æ£€æµ‹åˆ°M4èŠ¯ç‰‡: {chip_info}")
                # M4èŠ¯ç‰‡ä¼˜åŒ–é…ç½®
                # 1. æ–‡æœ¬åˆ‡åˆ† - CPUå¯†é›†å‹ï¼Œä½†ä¸éœ€è¦å¤ªå¤šå†…å­˜
                num_chunk_processes = max(2, physical_cores - 2)
                
                # 2. åµŒå…¥è®¡ç®— - MPS (GPU) ç“¶é¢ˆä»»åŠ¡
                # M4 MPSæ”¯æŒå¼‚æ­¥æ‰§è¡Œä½†å¹¶è¡Œæ€§æœ‰é™
                # é€šå¸¸2-3ä¸ªè¿›ç¨‹èƒ½è¾¾åˆ°æœ€ä½³å¹³è¡¡
                num_embedding_processes = 2  
                
                # 3. é˜Ÿåˆ—å¤§å°ä¼˜åŒ–
                chunk_queue_size = 5000  # è¾ƒå°çš„ç¼“å†²åŒºï¼Œé˜²æ­¢å†…å­˜è¿‡è½½
                result_queue_size = 10000  # é€‚ä¸­çš„ç»“æœç¼“å†²åŒº
                
                # 4. æ•°æ®åº“å¹¶å‘å†™å…¥è¿æ¥
                db_pool_size = min(physical_cores, 6)
                
                # 5. è®¾ç½®åµŒå…¥æ‰¹å¤„ç†å¤§å°
                embedding_batch_size = 512  # é™ä½æ‰¹å¤„ç†å¤§å°æé«˜å“åº”æ€§
            else:
                # å…¶ä»–Apple SiliconèŠ¯ç‰‡
                logger.info(f"æ£€æµ‹åˆ°å…¶ä»–Apple SiliconèŠ¯ç‰‡: {chip_info}")
                num_chunk_processes = max(2, physical_cores // 2)
                num_embedding_processes = min(3, physical_cores // 4) 
                chunk_queue_size = 4000
                result_queue_size = 6000
                db_pool_size = min(physical_cores // 2, 4)
                embedding_batch_size = 256
        except:
            # æ— æ³•æ£€æµ‹å…·ä½“å‹å·ï¼Œä½¿ç”¨é€šç”¨é…ç½®
            logger.info("ä½¿ç”¨é€šç”¨Apple Siliconä¼˜åŒ–")
            num_chunk_processes = max(2, physical_cores // 2)
            num_embedding_processes = 2
            chunk_queue_size = 4000
            result_queue_size = 6000
            db_pool_size = 4
            embedding_batch_size = 256
    else:
        # éApple Siliconä¼˜åŒ–
        logger.info("ä½¿ç”¨é€šç”¨ä¼˜åŒ–é…ç½®")
        num_chunk_processes = max(2, physical_cores // 2)
        num_embedding_processes = min(2, max(1, physical_cores // 4))
        chunk_queue_size = 2500
        result_queue_size = 4000
        db_pool_size = min(physical_cores // 2, 8)
        embedding_batch_size = 256
    
    # æ‰“å°ä¼˜åŒ–é…ç½®
    logger.info(f"ğŸ“Š ä¼˜åŒ–é…ç½®:")
    logger.info(f"  â†’ æ–‡æœ¬åˆ‡åˆ†è¿›ç¨‹æ•°: {num_chunk_processes}")
    logger.info(f"  â†’ åµŒå…¥è®¡ç®—è¿›ç¨‹æ•°: {num_embedding_processes}")
    logger.info(f"  â†’ æ•°æ®åº“è¿æ¥æ± å¤§å°: {db_pool_size}")
    logger.info(f"  â†’ åµŒå…¥æ‰¹å¤„ç†å¤§å°: {embedding_batch_size}")
    logger.info(f"  â†’ æ–‡æœ¬å—é˜Ÿåˆ—å¤§å°: {chunk_queue_size}")
    logger.info(f"  â†’ ç»“æœé˜Ÿåˆ—å¤§å°: {result_queue_size}")
    
    return {
        'num_chunk_processes': num_chunk_processes,
        'num_embedding_processes': num_embedding_processes,
        'chunk_queue_size': chunk_queue_size,
        'result_queue_size': result_queue_size,
        'db_pool_size': db_pool_size,
        'embedding_batch_size': embedding_batch_size
    }

# åˆå§‹åŒ–è®¾å¤‡
device = init_device()